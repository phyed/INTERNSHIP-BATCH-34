{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd491fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c3b7d5",
   "metadata": {},
   "source": [
    "-----DID THESE STEPS IN EACH PROGRAM------\n",
    "STEP 1: driver connection\n",
    "STEP2: link with autonomous website\n",
    "STEP3: search access\n",
    "STEP4: empty list creation to scrape necessary articles\n",
    "STEP5: print/df representation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d0cde",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd6eb9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\phyed\\Desktop\\FLIP ROBO ASSIGNMENT\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1716b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2cb11c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Series----- \n",
      " ['', 'INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19', '', 'INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19', '', 'SRI LANKA TOUR OF INDIA T20 SERIES 2022-23', '', 'INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19', '', 'SRI LANKA TOUR OF INDIA T20 SERIES 2022-23']\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "---Matches---- \n",
      " ['India Women U19\\nvs\\nSouth Africa Women U19', 'India Women U19\\nvs\\nSouth Africa Women U19', 'India\\nvs\\nSri Lanka', 'India Women U19\\nvs\\nSouth Africa Women U19', 'India\\nvs\\nSri Lanka', 'India\\nvs\\nSri Lanka', 'India\\nvs\\nSri Lanka', 'India\\nvs\\nSri Lanka', 'India\\nvs\\nSri Lanka', 'India\\nvs\\nNew Zealand']\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "----Date---- \n",
      " ['31 DEC 2022', '2 JAN 2023', '3 JAN 2023', '4 JAN 2023', '5 JAN 2023', '7 JAN 2023', '10 JAN 2023', '12 JAN 2023', '15 JAN 2023', '18 JAN 2023']\n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "Time \n",
      " ['1:30 PM IST', '5:15 PM IST', '7:00 PM IST', '1:30 PM IST', '7:00 PM IST', '7:00 PM IST', '1:30 PM IST', '1:30 PM IST', '1:30 PM IST', '1:30 PM IST']\n",
      "-----------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Match</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>India Women U19\\nvs\\nSouth Africa Women U19</td>\n",
       "      <td>31 DEC 2022</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19</td>\n",
       "      <td>India Women U19\\nvs\\nSouth Africa Women U19</td>\n",
       "      <td>2 JAN 2023</td>\n",
       "      <td>5:15 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>India\\nvs\\nSri Lanka</td>\n",
       "      <td>3 JAN 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19</td>\n",
       "      <td>India Women U19\\nvs\\nSouth Africa Women U19</td>\n",
       "      <td>4 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>India\\nvs\\nSri Lanka</td>\n",
       "      <td>5 JAN 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>India\\nvs\\nSri Lanka</td>\n",
       "      <td>7 JAN 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>India\\nvs\\nSri Lanka</td>\n",
       "      <td>10 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19</td>\n",
       "      <td>India\\nvs\\nSri Lanka</td>\n",
       "      <td>12 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>India\\nvs\\nSri Lanka</td>\n",
       "      <td>15 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23</td>\n",
       "      <td>India\\nvs\\nNew Zealand</td>\n",
       "      <td>18 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Series  \\\n",
       "0                                                   \n",
       "1  INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19   \n",
       "2                                                   \n",
       "3  INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19   \n",
       "4                                                   \n",
       "5      SRI LANKA TOUR OF INDIA T20 SERIES 2022-23   \n",
       "6                                                   \n",
       "7  INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19   \n",
       "8                                                   \n",
       "9      SRI LANKA TOUR OF INDIA T20 SERIES 2022-23   \n",
       "\n",
       "                                         Match         Date         Time  \n",
       "0  India Women U19\\nvs\\nSouth Africa Women U19  31 DEC 2022  1:30 PM IST  \n",
       "1  India Women U19\\nvs\\nSouth Africa Women U19   2 JAN 2023  5:15 PM IST  \n",
       "2                         India\\nvs\\nSri Lanka   3 JAN 2023  7:00 PM IST  \n",
       "3  India Women U19\\nvs\\nSouth Africa Women U19   4 JAN 2023  1:30 PM IST  \n",
       "4                         India\\nvs\\nSri Lanka   5 JAN 2023  7:00 PM IST  \n",
       "5                         India\\nvs\\nSri Lanka   7 JAN 2023  7:00 PM IST  \n",
       "6                         India\\nvs\\nSri Lanka  10 JAN 2023  1:30 PM IST  \n",
       "7                         India\\nvs\\nSri Lanka  12 JAN 2023  1:30 PM IST  \n",
       "8                         India\\nvs\\nSri Lanka  15 JAN 2023  1:30 PM IST  \n",
       "9                       India\\nvs\\nNew Zealand  18 JAN 2023  1:30 PM IST  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "title=[]\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//h5[@class=\"fix-text\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title.append(i.text)\n",
    "    \n",
    "print('-----Series-----','\\n',title)\n",
    "\n",
    "print('-----------------------------------------------------------------------------------------------------------------------')\n",
    "match=[]\n",
    "match_tags=driver.find_elements(By.XPATH,'//div[@class=\"fixture-card-mid d-flex align-items-center justify-content-between\"]')\n",
    "for i in match_tags[0:10]:\n",
    "    match.append(i.text)\n",
    "    \n",
    "print('---Matches----','\\n',match)\n",
    "\n",
    "print('-----------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "date=[]\n",
    "date_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-card-left match-schedule\"]')\n",
    "for i in date_tags[0:10]:\n",
    "    date.append(i.text)\n",
    "    \n",
    "print('----Date----','\\n',date)\n",
    "\n",
    "print('-----------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "time=[]\n",
    "time_tags=driver.find_elements(By.XPATH,'//div[@class=\"match-card-right match-schedule \"]')\n",
    "for i in time_tags[0:10]:\n",
    "    time.append(i.text)\n",
    "print(\"Time\",'\\n',time)\n",
    "\n",
    "print('-----------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "import pandas as pd\n",
    "df_match=pd.DataFrame({'Series':title,'Match':match,'Date':date,'Time':time})\n",
    "df_match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117945cd",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbaac6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\phyed\\Desktop\\FLIP ROBO ASSIGNMENT\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b8effbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://github.com/search?q=trending+repository')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b2ca213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QasimWani/LeetHub',\n",
       " 'vitalets/github-trending-repos',\n",
       " 'mbadry1/Trending-Deep-Learning',\n",
       " 'laowch/GithubTrends',\n",
       " 'ophobe/trending',\n",
       " 'zhuowenli/githuber',\n",
       " 'andygrunwald/TrendingGithub',\n",
       " 'andygrunwald/go-trending',\n",
       " 'karlrupp/microprocessor-trend-data']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo=[]\n",
    "repo_tags=driver.find_elements(By.XPATH,'//div[@class=\"f4 text-normal\"]')\n",
    "for i in repo_tags[0:9]:\n",
    "    repo.append(i.text)\n",
    "repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39fc2d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Automatically sync your leetcode solutions to your github account - top 5 trending GitHub repository',\n",
       " 'Track GitHub trending repositories in your favorite programming language by native GitHub notifications!',\n",
       " 'Top 100 trending deep learning repositories sorted by the number of stars gained on a specific day.',\n",
       " \"It's a GitHub Trending repositories Viewer with Material Design.\",\n",
       " 'Dataset of trending repositories on GitHub',\n",
       " 'Display Github Trending repositories on Chrome New Tab Extensions',\n",
       " 'A twitter bot (@TrendingGithub) to tweet trending repositories and developers from GitHub',\n",
       " 'Go library for accessing trending repositories and developers at Github.',\n",
       " 'Data repository for my blog series on microprocessor trend data.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "des=[]\n",
    "des_tags=driver.find_elements(By.XPATH,'//p[@class=\"mb-1\"]')\n",
    "for i in des_tags[0:9]:\n",
    "    des.append(i.text)\n",
    "des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e230f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.8k', '2.4k', '574', '634', '59', '458', '111', '122', '350']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_count=[]\n",
    "cont=driver.find_elements(By.XPATH,'//a[@class=\"Link--muted\"]')\n",
    "for i in cont[0:9]:\n",
    "    cont_count.append(i.text)\n",
    "cont_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e132fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JavaScript',\n",
       " 'HTML',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'JavaScript',\n",
       " 'Go',\n",
       " 'Go',\n",
       " 'Gnuplot',\n",
       " 'Java']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang=[]\n",
    "lang_tags=driver.find_elements(By.XPATH,'//span[@itemprop=\"programmingLanguage\"]')\n",
    "for i in lang_tags:\n",
    "    lang.append(i.text)\n",
    "lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e21cae58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REPOSITORY</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>CONTRIBUTION COUNT</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QasimWani/LeetHub</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>2.8k</td>\n",
       "      <td>Automatically sync your leetcode solutions to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vitalets/github-trending-repos</td>\n",
       "      <td>HTML</td>\n",
       "      <td>2.4k</td>\n",
       "      <td>Track GitHub trending repositories in your fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mbadry1/Trending-Deep-Learning</td>\n",
       "      <td>Python</td>\n",
       "      <td>574</td>\n",
       "      <td>Top 100 trending deep learning repositories so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>laowch/GithubTrends</td>\n",
       "      <td>Java</td>\n",
       "      <td>634</td>\n",
       "      <td>It's a GitHub Trending repositories Viewer wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ophobe/trending</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>59</td>\n",
       "      <td>Dataset of trending repositories on GitHub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zhuowenli/githuber</td>\n",
       "      <td>Go</td>\n",
       "      <td>458</td>\n",
       "      <td>Display Github Trending repositories on Chrome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>andygrunwald/TrendingGithub</td>\n",
       "      <td>Go</td>\n",
       "      <td>111</td>\n",
       "      <td>A twitter bot (@TrendingGithub) to tweet trend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>andygrunwald/go-trending</td>\n",
       "      <td>Gnuplot</td>\n",
       "      <td>122</td>\n",
       "      <td>Go library for accessing trending repositories...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>karlrupp/microprocessor-trend-data</td>\n",
       "      <td>Java</td>\n",
       "      <td>350</td>\n",
       "      <td>Data repository for my blog series on micropro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           REPOSITORY    LANGUAGE CONTRIBUTION COUNT  \\\n",
       "0                   QasimWani/LeetHub  JavaScript               2.8k   \n",
       "1      vitalets/github-trending-repos        HTML               2.4k   \n",
       "2      mbadry1/Trending-Deep-Learning      Python                574   \n",
       "3                 laowch/GithubTrends        Java                634   \n",
       "4                     ophobe/trending  JavaScript                 59   \n",
       "5                  zhuowenli/githuber          Go                458   \n",
       "6         andygrunwald/TrendingGithub          Go                111   \n",
       "7            andygrunwald/go-trending     Gnuplot                122   \n",
       "8  karlrupp/microprocessor-trend-data        Java                350   \n",
       "\n",
       "                                         DESCRIPTION  \n",
       "0  Automatically sync your leetcode solutions to ...  \n",
       "1  Track GitHub trending repositories in your fav...  \n",
       "2  Top 100 trending deep learning repositories so...  \n",
       "3  It's a GitHub Trending repositories Viewer wit...  \n",
       "4         Dataset of trending repositories on GitHub  \n",
       "5  Display Github Trending repositories on Chrome...  \n",
       "6  A twitter bot (@TrendingGithub) to tweet trend...  \n",
       "7  Go library for accessing trending repositories...  \n",
       "8  Data repository for my blog series on micropro...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'REPOSITORY':repo,'LANGUAGE':lang,'CONTRIBUTION COUNT':cont_count,'DESCRIPTION':des})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f93d7ce",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f255aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\phyed\\Desktop\\FLIP ROBO ASSIGNMENT\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "841de576",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "688edfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Game of Thrones (2011–2019)',\n",
       " '2. Stranger Things (2016– )',\n",
       " '3. The Walking Dead (2010–2022)',\n",
       " '4. 13 Reasons Why (2017–2020)',\n",
       " '5. The 100 (2014–2020)',\n",
       " '6. Orange Is the New Black (2013–2019)',\n",
       " '7. Riverdale (2017– )',\n",
       " \"8. Grey's Anatomy (2005– )\",\n",
       " '9. The Flash (2014–2023)',\n",
       " '10. Arrow (2012–2020)',\n",
       " '11. Money Heist (2017–2021)',\n",
       " '12. The Big Bang Theory (2007–2019)',\n",
       " '13. Black Mirror (2011–2019)',\n",
       " '14. Sherlock (2010–2017)',\n",
       " '15. Vikings (2013–2020)',\n",
       " '16. Pretty Little Liars (2010–2017)',\n",
       " '17. The Vampire Diaries (2009–2017)',\n",
       " '18. American Horror Story (2011– )',\n",
       " '19. Breaking Bad (2008–2013)',\n",
       " '20. Lucifer (2016–2021)',\n",
       " '21. Supernatural (2005–2020)',\n",
       " '22. Prison Break (2005–2017)',\n",
       " '23. How to Get Away with Murder (2014–2020)',\n",
       " '24. Teen Wolf (2011–2017)',\n",
       " '25. The Simpsons (1989– )',\n",
       " '26. Once Upon a Time (2011–2018)',\n",
       " '27. Narcos (2015–2017)',\n",
       " '28. Daredevil (2015–2018)',\n",
       " '29. Friends (1994–2004)',\n",
       " '30. How I Met Your Mother (2005–2014)',\n",
       " '31. Suits (2011–2019)',\n",
       " '32. Mr. Robot (2015–2019)',\n",
       " '33. The Originals (2013–2018)',\n",
       " '34. Supergirl (2015–2021)',\n",
       " '35. Gossip Girl (2007–2012)',\n",
       " '36. Sense8 (2015–2018)',\n",
       " '37. Gotham (2014–2019)',\n",
       " '38. Westworld (2016–2022)',\n",
       " '39. Jessica Jones (2015–2019)',\n",
       " '40. Modern Family (2009–2020)',\n",
       " '41. Rick and Morty (2013– )',\n",
       " '42. Shadowhunters (2016–2019)',\n",
       " '43. The End of the F***ing World (2017–2019)',\n",
       " '44. House of Cards (2013–2018)',\n",
       " '45. Dark (2017–2020)',\n",
       " '46. Elite (2018– )',\n",
       " '47. Sex Education (2019– )',\n",
       " '48. Shameless (2011–2021)',\n",
       " '49. New Girl (2011–2018)',\n",
       " '50. Agents of S.H.I.E.L.D. (2013–2020)']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvseries=[]\n",
    "tvseries_tags=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]')\n",
    "for i in tvseries_tags[0:50]:\n",
    "    tvseries.append(i.text)\n",
    "tvseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4b97bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '8.7',\n",
       " '8.1',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '8.1',\n",
       " '6.6',\n",
       " '7.6',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.8',\n",
       " '9.1',\n",
       " '8.5',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8',\n",
       " '9.5',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '7.7',\n",
       " '8.8',\n",
       " '8.6',\n",
       " '8.9',\n",
       " '8.3',\n",
       " '8.5',\n",
       " '8.6',\n",
       " '8.3',\n",
       " '6.2',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '7.8',\n",
       " '8.5',\n",
       " '7.9',\n",
       " '8.5',\n",
       " '9.1',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '7.3',\n",
       " '8.4',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.5']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]')[0:50]:\n",
    "    rating.append(i.text)\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fb6412b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime=[]\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]')[0:50]:\n",
    "    runtime.append(i.text)\n",
    "runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6c944ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Action, Adventure, Drama']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre=[]\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"genre\"]')[0:50]:\n",
    "    genre.append(i.text)\n",
    "genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d7f339f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,099,670',\n",
       " '1,189,934',\n",
       " '993,954',\n",
       " '294,153',\n",
       " '253,264',\n",
       " '303,862',\n",
       " '146,008',\n",
       " '310,684',\n",
       " '347,214',\n",
       " '432,716',\n",
       " '478,644',\n",
       " '810,258',\n",
       " '549,139',\n",
       " '927,950',\n",
       " '534,054',\n",
       " '168,555',\n",
       " '323,491',\n",
       " '321,014',\n",
       " '1,885,551',\n",
       " '326,192',\n",
       " '447,533',\n",
       " '537,363',\n",
       " '152,944',\n",
       " '149,712',\n",
       " '408,874',\n",
       " '226,021',\n",
       " '423,921',\n",
       " '442,340',\n",
       " '997,720',\n",
       " '685,547',\n",
       " '412,639',\n",
       " '389,124',\n",
       " '137,162',\n",
       " '124,710',\n",
       " '176,172',\n",
       " '155,394',\n",
       " '231,462',\n",
       " '506,810',\n",
       " '215,773',\n",
       " '432,850',\n",
       " '525,511',\n",
       " '64,459',\n",
       " '192,578',\n",
       " '505,864',\n",
       " '390,539',\n",
       " '80,471',\n",
       " '283,218',\n",
       " '244,559',\n",
       " '226,116',\n",
       " '218,014']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes=[]\n",
    "for i in driver.find_elements(By.XPATH,'//span[@name=\"nv\"]')[0:50]:\n",
    "    votes.append(i.text)\n",
    "votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab165ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TVSERIES</th>\n",
       "      <th>GENRE</th>\n",
       "      <th>RATING</th>\n",
       "      <th>RUNTIME</th>\n",
       "      <th>VOTES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones (2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>9.2</td>\n",
       "      <td>57 min</td>\n",
       "      <td>2,099,670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Stranger Things (2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>8.7</td>\n",
       "      <td>51 min</td>\n",
       "      <td>1,189,934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Walking Dead (2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>8.1</td>\n",
       "      <td>44 min</td>\n",
       "      <td>993,954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. 13 Reasons Why (2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>7.5</td>\n",
       "      <td>60 min</td>\n",
       "      <td>294,153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The 100 (2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>7.6</td>\n",
       "      <td>43 min</td>\n",
       "      <td>253,264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6. Orange Is the New Black (2013–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>8.1</td>\n",
       "      <td>59 min</td>\n",
       "      <td>303,862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7. Riverdale (2017– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>6.6</td>\n",
       "      <td>45 min</td>\n",
       "      <td>146,008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8. Grey's Anatomy (2005– )</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>7.6</td>\n",
       "      <td>41 min</td>\n",
       "      <td>310,684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9. The Flash (2014–2023)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>7.6</td>\n",
       "      <td>43 min</td>\n",
       "      <td>347,214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10. Arrow (2012–2020)</td>\n",
       "      <td>Action, Adventure, Crime</td>\n",
       "      <td>7.5</td>\n",
       "      <td>42 min</td>\n",
       "      <td>432,716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11. Money Heist (2017–2021)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>8.2</td>\n",
       "      <td>70 min</td>\n",
       "      <td>478,644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12. The Big Bang Theory (2007–2019)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>8.2</td>\n",
       "      <td>22 min</td>\n",
       "      <td>810,258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13. Black Mirror (2011–2019)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>8.8</td>\n",
       "      <td>60 min</td>\n",
       "      <td>549,139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14. Sherlock (2010–2017)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>9.1</td>\n",
       "      <td>88 min</td>\n",
       "      <td>927,950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15. Vikings (2013–2020)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>8.5</td>\n",
       "      <td>44 min</td>\n",
       "      <td>534,054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16. Pretty Little Liars (2010–2017)</td>\n",
       "      <td>Drama, Mystery, Romance</td>\n",
       "      <td>7.4</td>\n",
       "      <td>44 min</td>\n",
       "      <td>168,555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17. The Vampire Diaries (2009–2017)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>7.7</td>\n",
       "      <td>43 min</td>\n",
       "      <td>323,491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18. American Horror Story (2011– )</td>\n",
       "      <td>Drama, Horror, Sci-Fi</td>\n",
       "      <td>8</td>\n",
       "      <td>60 min</td>\n",
       "      <td>321,014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19. Breaking Bad (2008–2013)</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>9.5</td>\n",
       "      <td>49 min</td>\n",
       "      <td>1,885,551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20. Lucifer (2016–2021)</td>\n",
       "      <td>Crime, Drama, Fantasy</td>\n",
       "      <td>8.1</td>\n",
       "      <td>42 min</td>\n",
       "      <td>326,192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21. Supernatural (2005–2020)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>8.4</td>\n",
       "      <td>44 min</td>\n",
       "      <td>447,533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22. Prison Break (2005–2017)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>8.3</td>\n",
       "      <td>44 min</td>\n",
       "      <td>537,363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23. How to Get Away with Murder (2014–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>8.1</td>\n",
       "      <td>43 min</td>\n",
       "      <td>152,944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24. Teen Wolf (2011–2017)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>7.7</td>\n",
       "      <td>41 min</td>\n",
       "      <td>149,712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25. The Simpsons (1989– )</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>8.7</td>\n",
       "      <td>22 min</td>\n",
       "      <td>408,874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26. Once Upon a Time (2011–2018)</td>\n",
       "      <td>Adventure, Fantasy, Romance</td>\n",
       "      <td>7.7</td>\n",
       "      <td>60 min</td>\n",
       "      <td>226,021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27. Narcos (2015–2017)</td>\n",
       "      <td>Biography, Crime, Drama</td>\n",
       "      <td>8.8</td>\n",
       "      <td>49 min</td>\n",
       "      <td>423,921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28. Daredevil (2015–2018)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>8.6</td>\n",
       "      <td>54 min</td>\n",
       "      <td>442,340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29. Friends (1994–2004)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>8.9</td>\n",
       "      <td>22 min</td>\n",
       "      <td>997,720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30. How I Met Your Mother (2005–2014)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>8.3</td>\n",
       "      <td>22 min</td>\n",
       "      <td>685,547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31. Suits (2011–2019)</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>8.5</td>\n",
       "      <td>44 min</td>\n",
       "      <td>412,639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32. Mr. Robot (2015–2019)</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>8.6</td>\n",
       "      <td>49 min</td>\n",
       "      <td>389,124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33. The Originals (2013–2018)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>8.3</td>\n",
       "      <td>45 min</td>\n",
       "      <td>137,162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34. Supergirl (2015–2021)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>6.2</td>\n",
       "      <td>43 min</td>\n",
       "      <td>124,710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35. Gossip Girl (2007–2012)</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>7.5</td>\n",
       "      <td>42 min</td>\n",
       "      <td>176,172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36. Sense8 (2015–2018)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>8.2</td>\n",
       "      <td>60 min</td>\n",
       "      <td>155,394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37. Gotham (2014–2019)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>7.8</td>\n",
       "      <td>42 min</td>\n",
       "      <td>231,462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38. Westworld (2016–2022)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>8.5</td>\n",
       "      <td>62 min</td>\n",
       "      <td>506,810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39. Jessica Jones (2015–2019)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>7.9</td>\n",
       "      <td>56 min</td>\n",
       "      <td>215,773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40. Modern Family (2009–2020)</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>8.5</td>\n",
       "      <td>22 min</td>\n",
       "      <td>432,850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41. Rick and Morty (2013– )</td>\n",
       "      <td>Animation, Adventure, Comedy</td>\n",
       "      <td>9.1</td>\n",
       "      <td>23 min</td>\n",
       "      <td>525,511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42. Shadowhunters (2016–2019)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>6.5</td>\n",
       "      <td>42 min</td>\n",
       "      <td>64,459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43. The End of the F***ing World (2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Crime</td>\n",
       "      <td>8.1</td>\n",
       "      <td>25 min</td>\n",
       "      <td>192,578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44. House of Cards (2013–2018)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>8.7</td>\n",
       "      <td>51 min</td>\n",
       "      <td>505,864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45. Dark (2017–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>8.7</td>\n",
       "      <td>60 min</td>\n",
       "      <td>390,539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46. Elite (2018– )</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>7.3</td>\n",
       "      <td>60 min</td>\n",
       "      <td>80,471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47. Sex Education (2019– )</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>8.4</td>\n",
       "      <td>45 min</td>\n",
       "      <td>283,218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48. Shameless (2011–2021)</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>8.6</td>\n",
       "      <td>46 min</td>\n",
       "      <td>244,559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49. New Girl (2011–2018)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>7.8</td>\n",
       "      <td>22 min</td>\n",
       "      <td>226,116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50. Agents of S.H.I.E.L.D. (2013–2020)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>7.5</td>\n",
       "      <td>45 min</td>\n",
       "      <td>218,014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        TVSERIES  \\\n",
       "0                 1. Game of Thrones (2011–2019)   \n",
       "1                    2. Stranger Things (2016– )   \n",
       "2                3. The Walking Dead (2010–2022)   \n",
       "3                  4. 13 Reasons Why (2017–2020)   \n",
       "4                         5. The 100 (2014–2020)   \n",
       "5         6. Orange Is the New Black (2013–2019)   \n",
       "6                          7. Riverdale (2017– )   \n",
       "7                     8. Grey's Anatomy (2005– )   \n",
       "8                       9. The Flash (2014–2023)   \n",
       "9                          10. Arrow (2012–2020)   \n",
       "10                   11. Money Heist (2017–2021)   \n",
       "11           12. The Big Bang Theory (2007–2019)   \n",
       "12                  13. Black Mirror (2011–2019)   \n",
       "13                      14. Sherlock (2010–2017)   \n",
       "14                       15. Vikings (2013–2020)   \n",
       "15           16. Pretty Little Liars (2010–2017)   \n",
       "16           17. The Vampire Diaries (2009–2017)   \n",
       "17            18. American Horror Story (2011– )   \n",
       "18                  19. Breaking Bad (2008–2013)   \n",
       "19                       20. Lucifer (2016–2021)   \n",
       "20                  21. Supernatural (2005–2020)   \n",
       "21                  22. Prison Break (2005–2017)   \n",
       "22   23. How to Get Away with Murder (2014–2020)   \n",
       "23                     24. Teen Wolf (2011–2017)   \n",
       "24                     25. The Simpsons (1989– )   \n",
       "25              26. Once Upon a Time (2011–2018)   \n",
       "26                        27. Narcos (2015–2017)   \n",
       "27                     28. Daredevil (2015–2018)   \n",
       "28                       29. Friends (1994–2004)   \n",
       "29         30. How I Met Your Mother (2005–2014)   \n",
       "30                         31. Suits (2011–2019)   \n",
       "31                     32. Mr. Robot (2015–2019)   \n",
       "32                 33. The Originals (2013–2018)   \n",
       "33                     34. Supergirl (2015–2021)   \n",
       "34                   35. Gossip Girl (2007–2012)   \n",
       "35                        36. Sense8 (2015–2018)   \n",
       "36                        37. Gotham (2014–2019)   \n",
       "37                     38. Westworld (2016–2022)   \n",
       "38                 39. Jessica Jones (2015–2019)   \n",
       "39                 40. Modern Family (2009–2020)   \n",
       "40                   41. Rick and Morty (2013– )   \n",
       "41                 42. Shadowhunters (2016–2019)   \n",
       "42  43. The End of the F***ing World (2017–2019)   \n",
       "43                44. House of Cards (2013–2018)   \n",
       "44                          45. Dark (2017–2020)   \n",
       "45                            46. Elite (2018– )   \n",
       "46                    47. Sex Education (2019– )   \n",
       "47                     48. Shameless (2011–2021)   \n",
       "48                      49. New Girl (2011–2018)   \n",
       "49        50. Agents of S.H.I.E.L.D. (2013–2020)   \n",
       "\n",
       "                           GENRE RATING RUNTIME      VOTES  \n",
       "0       Action, Adventure, Drama    9.2  57 min  2,099,670  \n",
       "1         Drama, Fantasy, Horror    8.7  51 min  1,189,934  \n",
       "2        Drama, Horror, Thriller    8.1  44 min    993,954  \n",
       "3       Drama, Mystery, Thriller    7.5  60 min    294,153  \n",
       "4         Drama, Mystery, Sci-Fi    7.6  43 min    253,264  \n",
       "5           Comedy, Crime, Drama    8.1  59 min    303,862  \n",
       "6          Crime, Drama, Mystery    6.6  45 min    146,008  \n",
       "7                 Drama, Romance    7.6  41 min    310,684  \n",
       "8       Action, Adventure, Drama    7.6  43 min    347,214  \n",
       "9       Action, Adventure, Crime    7.5  42 min    432,716  \n",
       "10          Action, Crime, Drama    8.2  70 min    478,644  \n",
       "11               Comedy, Romance    8.2  22 min    810,258  \n",
       "12        Drama, Mystery, Sci-Fi    8.8  60 min    549,139  \n",
       "13         Crime, Drama, Mystery    9.1  88 min    927,950  \n",
       "14      Action, Adventure, Drama    8.5  44 min    534,054  \n",
       "15       Drama, Mystery, Romance    7.4  44 min    168,555  \n",
       "16        Drama, Fantasy, Horror    7.7  43 min    323,491  \n",
       "17         Drama, Horror, Sci-Fi      8  60 min    321,014  \n",
       "18        Crime, Drama, Thriller    9.5  49 min  1,885,551  \n",
       "19         Crime, Drama, Fantasy    8.1  42 min    326,192  \n",
       "20        Drama, Fantasy, Horror    8.4  44 min    447,533  \n",
       "21          Action, Crime, Drama    8.3  44 min    537,363  \n",
       "22         Crime, Drama, Mystery    8.1  43 min    152,944  \n",
       "23        Action, Drama, Fantasy    7.7  41 min    149,712  \n",
       "24             Animation, Comedy    8.7  22 min    408,874  \n",
       "25   Adventure, Fantasy, Romance    7.7  60 min    226,021  \n",
       "26       Biography, Crime, Drama    8.8  49 min    423,921  \n",
       "27          Action, Crime, Drama    8.6  54 min    442,340  \n",
       "28               Comedy, Romance    8.9  22 min    997,720  \n",
       "29               Comedy, Romance    8.3  22 min    685,547  \n",
       "30                 Comedy, Drama    8.5  44 min    412,639  \n",
       "31        Crime, Drama, Thriller    8.6  49 min    389,124  \n",
       "32        Drama, Fantasy, Horror    8.3  45 min    137,162  \n",
       "33      Action, Adventure, Drama    6.2  43 min    124,710  \n",
       "34                Drama, Romance    7.5  42 min    176,172  \n",
       "35        Drama, Mystery, Sci-Fi    8.2  60 min    155,394  \n",
       "36          Action, Crime, Drama    7.8  42 min    231,462  \n",
       "37        Drama, Mystery, Sci-Fi    8.5  62 min    506,810  \n",
       "38          Action, Crime, Drama    7.9  56 min    215,773  \n",
       "39        Comedy, Drama, Romance    8.5  22 min    432,850  \n",
       "40  Animation, Adventure, Comedy    9.1  23 min    525,511  \n",
       "41        Action, Drama, Fantasy    6.5  42 min     64,459  \n",
       "42      Adventure, Comedy, Crime    8.1  25 min    192,578  \n",
       "43                         Drama    8.7  51 min    505,864  \n",
       "44         Crime, Drama, Mystery    8.7  60 min    390,539  \n",
       "45        Crime, Drama, Thriller    7.3  60 min     80,471  \n",
       "46                 Comedy, Drama    8.4  45 min    283,218  \n",
       "47                 Comedy, Drama    8.6  46 min    244,559  \n",
       "48               Comedy, Romance    7.8  22 min    226,116  \n",
       "49      Action, Adventure, Drama    7.5  45 min    218,014  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'TVSERIES':tvseries,'GENRE':genre,'RATING':rating,'RUNTIME':runtime,'VOTES':votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15c568a",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19fe2cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\phyed\\Desktop\\FLIP ROBO ASSIGNMENT\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3fc83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "14beed08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['music videos',\n",
       " 'regional restrictions',\n",
       " 'Baby Shark Dance',\n",
       " 'Johny Johny Yes Papa',\n",
       " 'Cocomelon – Nursery Rhymes']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoname=[]\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"mw-redirect\"]')[0:5]:\n",
    "    videoname.append(i.text)\n",
    "videoname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2c2464c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'October 8, 2016',\n",
       " 'May 2, 2018',\n",
       " 'January 30, 2017']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish_date=[]\n",
    "for i in driver.find_elements(By.XPATH,'//td[@align=\"right\"]')[0:5]:\n",
    "    publish_date.append(i.text)\n",
    "publish_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd39e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Pinkfong Baby Shark - Kids' Songs & Stories\"]\n",
      "['Luis Fonsi']\n",
      "['LooLoo Kids']\n",
      "['Cocomelon – Nursery Rhymes']\n",
      "['Ed Sheeran']\n"
     ]
    }
   ],
   "source": [
    "uploader1=[]\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[3]/div[3]/div[5]/div[1]/table[2]/tbody/tr[1]/td[3]/a'):\n",
    "    uploader1.append(i.text)\n",
    "print(uploader1)\n",
    "\n",
    "uploader2=[]\n",
    "uploader3=[]\n",
    "uploader4=[]\n",
    "uploader5=[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[3]/div[3]/div[5]/div[1]/table[2]/tbody/tr[2]/td[3]/a'):\n",
    "    \n",
    "    uploader2.append(i.text)\n",
    "print(uploader2) \n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[3]/div[3]/div[5]/div[1]/table[2]/tbody/tr[3]/td[3]'):\n",
    "    \n",
    "    uploader3.append(i.text)\n",
    "print(uploader3) \n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[3]/div[3]/div[5]/div[1]/table[2]/tbody/tr[4]/td[3]/a'):\n",
    "    \n",
    "    uploader4.append(i.text)\n",
    "print(uploader4) \n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[3]/div[3]/div[5]/div[1]/table[2]/tbody/tr[5]/td[3]/a'):\n",
    "    uploader5.append(i.text)\n",
    "print(uploader5) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6dc12de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.', '12.00', '[A]', '2.', '8.05', '[B]', '3.', '6.57', '[C]', '4.', '5.89', '[D]', '5.', '5.88', '[E]'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view=[]\n",
    "for i in driver.find_elements(By.XPATH,'//td[@align=\"center\"]')[0:15]:\n",
    "    view.append(i.text)\n",
    "print(view,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e517a0",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e944db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\phyed\\Desktop\\FLIP ROBO ASSIGNMENT\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2dd975d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cceb5bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'Da Vinci Code,The', 'Brown, Dan', '5,094,805', 'Transworld', '2', 'Harry Potter and the Deathly Hallows', 'Rowling, J.K.', '4,475,152', 'Bloomsbury', '3', \"Harry Potter and the Philosopher's Stone\", 'Rowling, J.K.', '4,200,654', 'Bloomsbury', '4', 'Harry Potter and the Order of the Phoenix', 'Rowling, J.K.', '4,179,479', 'Bloomsbury', '5', 'Fifty Shades of Grey', 'James, E. L.', '3,758,936', 'Random House', '6', 'Harry Potter and the Goblet of Fire', 'Rowling, J.K.', '3,583,215', 'Bloomsbury', '7', 'Harry Potter and the Chamber of Secrets', 'Rowling, J.K.', '3,484,047', 'Bloomsbury', '8', 'Harry Potter and the Prisoner of Azkaban', 'Rowling, J.K.', '3,377,906', 'Bloomsbury', '9', 'Angels and Demons', 'Brown, Dan', '3,193,946', 'Transworld', '10', \"Harry Potter and the Half-blood Prince:Children's Edition\", 'Rowling, J.K.', '2,950,264', 'Bloomsbury', '11', 'Fifty Shades Darker', 'James, E. L.', '2,479,784', 'Random House', '12', 'Twilight', 'Meyer, Stephenie', '2,315,405', 'Little, Brown Book', '13', 'Girl with the Dragon Tattoo,The:Millennium Trilogy', 'Larsson, Stieg', '2,233,570', 'Quercus', '14', 'Fifty Shades Freed', 'James, E. L.', '2,193,928', 'Random House', '15', 'Lost Symbol,The', 'Brown, Dan', '2,183,031', 'Transworld', '16', 'New Moon', 'Meyer, Stephenie', '2,152,737', 'Little, Brown Book', '17', 'Deception Point', 'Brown, Dan', '2,062,145', 'Transworld', '18', 'Eclipse', 'Meyer, Stephenie', '2,052,876', 'Little, Brown Book', '19', 'Lovely Bones,The', 'Sebold, Alice', '2,005,598', 'Pan Macmillan', '20', 'Curious Incident of the Dog in the Night-time,The', 'Haddon, Mark', '1,979,552', 'Random House'] /n\n"
     ]
    }
   ],
   "source": [
    "booktitle=[]\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"left\"]')[0:100]:\n",
    "    booktitle.append(i.text)\n",
    "print(booktitle,'/n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db2df0",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "587274d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\phyed\\Desktop\\FLIP ROBO ASSIGNMENT\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "473835f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://www.guru99.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b82704d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search1=driver.find_element(By.CLASS_NAME,\"search-field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "db819cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "search1.send_keys('selenium exceptions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "01e15b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "search2=driver.find_element(By.CLASS_NAME,\"search-submit\")\n",
    "search2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8b05b2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL EXCEPTIONS ALONG WITH DESCRIPTION------------\n",
      "['1. ElementNotVisibleException: This type of Selenium exception occurs when an existing element in DOM has a feature set as hidden.']\n",
      "['2. ElementNotSelectableException: This Selenium exception occurs when an element is presented in the DOM, but you can be able to select. Therefore, it is not possible to interact.']\n",
      "['3. NoSuchElementException: This Exception occurs if an element could not be found.']\n",
      "['4. NoSuchFrameException: This Exception occurs if the frame target to be switched to does not exist.']\n",
      "['5. NoAlertPresentException: This Exception occurs when you switch to no presented alert.']\n"
     ]
    }
   ],
   "source": [
    "print('ALL EXCEPTIONS ALONG WITH DESCRIPTION------------')\n",
    "des1=[]\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[1]'):\n",
    "    des1.append(i.text)\n",
    "\n",
    "\n",
    "print(des1)    \n",
    "\n",
    "\n",
    "des2=[]\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[2]'):\n",
    "    des2.append(i.text)\n",
    "print(des2)\n",
    "\n",
    "des3=[]\n",
    "des4=[]\n",
    "des5=[]\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[3]'):\n",
    "    des3.append(i.text)\n",
    "print(des3)\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[4]'):\n",
    "    des4.append(i.text)\n",
    "print(des4)\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p[5]'):\n",
    "    des5.append(i.text)\n",
    "print(des5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d6b74",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "eac04aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\phyed\\Desktop\\FLIP ROBO ASSIGNMENT\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6aa4f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b5c8be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,'suggestor-input ')\n",
    "designation.send_keys('data science recruiters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "aa04275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3c6706cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB TITLES \n",
      " ['ACN - Applied Intelligence - Finance - Data Science - 09', 'ACN - Applied Intelligence - Finance - Data Science - 09', 'Python - Data Science Analyst', 'ACN - Applied Intelligence - CC - Data Science (IN) - 06', 'ACN - Applied Intelligence - Finance - Data Science - 09', 'ACN - Applied Intelligence - Finance - Data Science - 09', 'ACN - Applied Intelligence - Finance - Data Science - 09', 'Technology Analyst - Data Science / Machine Learning', 'Analyst - Data Science', 'SENIOR MANAGER I, DATA SCIENCE', 'Senior Manager II, Data Science', 'Data Science Professional', 'Data Analyst - Data Science', 'Senior Analyst & AI Lead - Data Science', 'Analyst / Senior Analyst Data Science & Strategy', 'SnapLogic Data Science Practitioner', 'ACN - Applied Intelligence - CC - Data Science (IN) - 09', 'Manager - Data Science']\n",
      "------------------------------------------------------------------------------------\n",
      "EXPERIENCE \n",
      " ['3-5 Yrs', '3-5 Yrs', '3-5 Yrs', '8-12 Yrs', '3-5 Yrs', '3-5 Yrs', '3-5 Yrs', '3-5 Yrs', '1-4 Yrs', '6-10 Yrs', '6-10 Yrs', '4-8 Yrs', '5-8 Yrs', '2-7 Yrs', '0-6 Yrs', '2-4 Yrs', '2-6 Yrs', '5-8 Yrs']\n",
      "------------------------------------------------------------------------------------\n",
      "LOCATION \n",
      " ['Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Bhubaneswar', 'Gurgaon/Gurugram', 'Chennai', 'Mumbai', 'Gurgaon/Gurugram', 'Bangalore/Bengaluru', 'Mumbai', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'Bangalore/Bengaluru', 'New Delhi, Faridabad, Gurgaon/Gurugram, Delhi / NCR', 'Gurgaon/Gurugram', 'Mumbai', 'Gurgaon/Gurugram', 'Mumbai']\n",
      "------------------------------------------------------------------------------------\n",
      "COMPANY NAME \n",
      " ['Accenture', 'Accenture', 'Infosys', 'Accenture', 'Accenture', 'Accenture', 'Accenture', 'Infosys', 'Visa', 'Walmart', 'Walmart', 'Infosys', 'Awign Enterprises', 'Huquo Consulting Pvt. Ltd', 'AMERICAN EXPRESS', 'Accenture', 'Accenture', 'Morningstar']\n",
      "------------------------------------------------------------------------------------\n",
      "SKILL \n",
      " ['Computer science', 'Data analysis', 'Healthcare', 'SDK', 'Analytics', 'Publishing', 'Analytical', 'Machine learning', 'Data analysis', 'Machine learning', 'Healthcare', 'SDK', 'Analytics', 'Publishing', 'Analytical', 'Vulnerability assessment', 'python', 'agile methodologies']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPANY NAME</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>SKILL</th>\n",
       "      <th>EXPERIENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>ACN - Applied Intelligence - Finance - Data Sc...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Computer science</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>ACN - Applied Intelligence - Finance - Data Sc...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data analysis</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>Python - Data Science Analyst</td>\n",
       "      <td>Bhubaneswar</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>SDK</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>ACN - Applied Intelligence - Finance - Data Sc...</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>ACN - Applied Intelligence - Finance - Data Sc...</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>ACN - Applied Intelligence - Finance - Data Sc...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Analytical</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>Technology Analyst - Data Science / Machine Le...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Machine learning</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Visa</td>\n",
       "      <td>Analyst - Data Science</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Data analysis</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>SENIOR MANAGER I, DATA SCIENCE</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Machine learning</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>Senior Manager II, Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>Data Science Professional</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>SDK</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Awign Enterprises</td>\n",
       "      <td>Data Analyst - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>Senior Analyst &amp; AI Lead - Data Science</td>\n",
       "      <td>New Delhi, Faridabad, Gurgaon/Gurugram, Delhi ...</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>Analyst / Senior Analyst Data Science &amp; Strategy</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Analytical</td>\n",
       "      <td>0-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>SnapLogic Data Science Practitioner</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Vulnerability assessment</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>python</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Morningstar</td>\n",
       "      <td>Manager - Data Science</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>agile methodologies</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 COMPANY NAME  \\\n",
       "0                   Accenture   \n",
       "1                   Accenture   \n",
       "2                     Infosys   \n",
       "3                   Accenture   \n",
       "4                   Accenture   \n",
       "5                   Accenture   \n",
       "6                   Accenture   \n",
       "7                     Infosys   \n",
       "8                        Visa   \n",
       "9                     Walmart   \n",
       "10                    Walmart   \n",
       "11                    Infosys   \n",
       "12          Awign Enterprises   \n",
       "13  Huquo Consulting Pvt. Ltd   \n",
       "14           AMERICAN EXPRESS   \n",
       "15                  Accenture   \n",
       "16                  Accenture   \n",
       "17                Morningstar   \n",
       "\n",
       "                                                TITLE  \\\n",
       "0   ACN - Applied Intelligence - Finance - Data Sc...   \n",
       "1   ACN - Applied Intelligence - Finance - Data Sc...   \n",
       "2                       Python - Data Science Analyst   \n",
       "3   ACN - Applied Intelligence - CC - Data Science...   \n",
       "4   ACN - Applied Intelligence - Finance - Data Sc...   \n",
       "5   ACN - Applied Intelligence - Finance - Data Sc...   \n",
       "6   ACN - Applied Intelligence - Finance - Data Sc...   \n",
       "7   Technology Analyst - Data Science / Machine Le...   \n",
       "8                              Analyst - Data Science   \n",
       "9                      SENIOR MANAGER I, DATA SCIENCE   \n",
       "10                    Senior Manager II, Data Science   \n",
       "11                          Data Science Professional   \n",
       "12                        Data Analyst - Data Science   \n",
       "13            Senior Analyst & AI Lead - Data Science   \n",
       "14   Analyst / Senior Analyst Data Science & Strategy   \n",
       "15                SnapLogic Data Science Practitioner   \n",
       "16  ACN - Applied Intelligence - CC - Data Science...   \n",
       "17                             Manager - Data Science   \n",
       "\n",
       "                                             LOCATION  \\\n",
       "0                                 Bangalore/Bengaluru   \n",
       "1                                 Bangalore/Bengaluru   \n",
       "2                                         Bhubaneswar   \n",
       "3                                    Gurgaon/Gurugram   \n",
       "4                                             Chennai   \n",
       "5                                              Mumbai   \n",
       "6                                    Gurgaon/Gurugram   \n",
       "7                                 Bangalore/Bengaluru   \n",
       "8                                              Mumbai   \n",
       "9                                 Bangalore/Bengaluru   \n",
       "10                                Bangalore/Bengaluru   \n",
       "11                                Bangalore/Bengaluru   \n",
       "12                                Bangalore/Bengaluru   \n",
       "13  New Delhi, Faridabad, Gurgaon/Gurugram, Delhi ...   \n",
       "14                                   Gurgaon/Gurugram   \n",
       "15                                             Mumbai   \n",
       "16                                   Gurgaon/Gurugram   \n",
       "17                                             Mumbai   \n",
       "\n",
       "                       SKILL EXPERIENCE  \n",
       "0           Computer science    3-5 Yrs  \n",
       "1              Data analysis    3-5 Yrs  \n",
       "2                 Healthcare    3-5 Yrs  \n",
       "3                        SDK   8-12 Yrs  \n",
       "4                  Analytics    3-5 Yrs  \n",
       "5                 Publishing    3-5 Yrs  \n",
       "6                 Analytical    3-5 Yrs  \n",
       "7           Machine learning    3-5 Yrs  \n",
       "8              Data analysis    1-4 Yrs  \n",
       "9           Machine learning   6-10 Yrs  \n",
       "10                Healthcare   6-10 Yrs  \n",
       "11                       SDK    4-8 Yrs  \n",
       "12                 Analytics    5-8 Yrs  \n",
       "13                Publishing    2-7 Yrs  \n",
       "14                Analytical    0-6 Yrs  \n",
       "15  Vulnerability assessment    2-4 Yrs  \n",
       "16                    python    2-6 Yrs  \n",
       "17       agile methodologies    5-8 Yrs  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title=[]\n",
    "location=[]\n",
    "company=[]\n",
    "exp=[]\n",
    "skill=[]\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')[0:18]:\n",
    "    title.append(i.text)\n",
    "print('JOB TITLES','\\n',title)\n",
    "\n",
    "print('------------------------------------------------------------------------------------')\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')[0:18]:\n",
    "    exp.append(i.text)\n",
    "print('EXPERIENCE','\\n',exp)\n",
    "\n",
    "print('------------------------------------------------------------------------------------')\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')[0:18]:\n",
    "    location.append(i.text)\n",
    "print('LOCATION','\\n',location)\n",
    "\n",
    "print('------------------------------------------------------------------------------------')\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')[0:18]:\n",
    "    company.append(i.text)\n",
    "print('COMPANY NAME','\\n',company)    \n",
    "\n",
    "print('------------------------------------------------------------------------------------')\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"fleft dot\"]')[0:18]:\n",
    "    skill.append(i.text)\n",
    "print('SKILL','\\n',skill)\n",
    "\n",
    "df=pd.DataFrame({'COMPANY NAME':company,'TITLE':title,'LOCATION':location,'SKILL':skill,'EXPERIENCE':exp})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f2900a",
   "metadata": {},
   "source": [
    "# Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16260535",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\phyed\\Desktop\\FLIP ROBO ASSIGNMENT\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121b9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3348c813",
   "metadata": {},
   "outputs": [],
   "source": [
    "search1=driver.find_element(By.XPATH,'//input[@name=\"q\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68403e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "search1.send_keys('Details of Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3b09d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "search2=driver.find_element(By.XPATH,'//input[@name=\"sa\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1baae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "search2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db6fe5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classification (466)\\nRegression (151)\\nClustering (121)\\nOther (56)',\n",
       " 'Categorical (38)\\nNumerical (422)\\nMixed (55)',\n",
       " 'Multivariate (480)\\nUnivariate (30)\\nSequential (59)\\nTime-Series (126)\\nText (69)\\nDomain-Theory (23)\\nOther (21)',\n",
       " 'Life Sciences (147)\\nPhysical Sciences (57)\\nCS / Engineering (234)\\nSocial Sciences (41)\\nBusiness (45)\\nGame (12)\\nOther (81)',\n",
       " 'Less than 10 (166)\\n10 to 100 (279)\\nGreater than 100 (110)',\n",
       " 'Less than 100 (38)\\n100 to 1000 (210)\\nGreater than 1000 (339)',\n",
       " 'Matrix (439)\\nNon-Matrix (183)',\n",
       " 'Table View  List View',\n",
       " '2.4 GHZ Indoor Channel Measurements',\n",
       " 'Multivariate ',\n",
       " 'Classification ',\n",
       " 'Real ',\n",
       " '7840 ',\n",
       " '5 ',\n",
       " '2018 ',\n",
       " '3D Road Network (North Jutland, Denmark)',\n",
       " 'Sequential, Text ',\n",
       " 'Regression, Clustering ',\n",
       " 'Real ',\n",
       " '434874 ',\n",
       " '4 ',\n",
       " '2013 ',\n",
       " '3W dataset',\n",
       " 'Multivariate, Time-Series ',\n",
       " 'Classification, Clustering ',\n",
       " 'Integer, Real ',\n",
       " '1984 ',\n",
       " '8 ',\n",
       " '2019 ',\n",
       " '9mers from cullpdb',\n",
       " 'Sequential ',\n",
       " 'Classification, Regression ',\n",
       " 'Real ',\n",
       " '158716 ',\n",
       " '4 ',\n",
       " '2021 ',\n",
       " ': Simulated Data set of Iraqi tourism places',\n",
       " 'Multivariate ',\n",
       " 'Classification, Clustering ',\n",
       " ' ',\n",
       " '232 ',\n",
       " '16 ',\n",
       " '2020 ',\n",
       " 'A study of Asian Religious and Biblical Texts',\n",
       " 'Multivariate, Text ',\n",
       " 'Classification, Clustering ',\n",
       " 'Integer ',\n",
       " '590 ',\n",
       " '8265 ',\n",
       " '2019 ']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=[]\n",
    "ds_tags=driver.find_elements(By.XPATH,'//p[@class=\"normal\"]')[0:50]\n",
    "for i in ds_tags:\n",
    "    ds.append(i.text)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac214118",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0528869",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\phyed\\Desktop\\FLIP ROBO ASSIGNMENT\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d4b0c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd177fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search1=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[4]/div/div[1]/div[3]/div[1]/div/div/div/form/label/input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "320e2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "search1.send_keys('top 100 songs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b96cd00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search2=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[4]/div/div[1]/div[3]/div[1]/div/div/div/form/input')\n",
    "search2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9c55eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs=[]\n",
    "for i in driver.find_elements(By.XPATH,'//h2[@class=\"c-gallery-vertical-featured-image__title\"]'):\n",
    "    songs.append(i.text)\n",
    "    \n",
    "peak=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"c-gallery-vertical-featured-image__description\"]'):\n",
    "    peak.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0dbbbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------TAYLOR SWIFTS SONGS----------- \n",
      " ['\"Should’ve Said No\"', '\"Everything Has Changed\" ft. Ed Sheeran', '\"Tim McGraw\"', '\"Bejeweled\"', '\"Eyes Open\"', '\"Red\"', '\"Midnight Rain\"', '\"Ours\"', '\"Lavender Haze\"', '\"Mean\"', 'Tim McGraw with Taylor Swift, “Highway Don’t Care”', '\"Fifteen\"', '\"22\"', '\"...Ready for It?\"', '\"Cardigan\"', '\"Lover\"', '\"White Horse\"', '\"All Too Well (Taylor\\'s Version)\"', '\"Today Was a Fairytale\"', 'Boys Like Girls ft. Taylor Swift, \"Two Is Better Than One\"', '\"Willow\"', '\"Back to December\"', '\"Delicate\"', '\"Me!\" ft. Brendon Urie', '\"You Need to Calm Down\"', '\"Our Song\"', '\"Teardrops on My Guitar\"', '\"Mine\"', '\"Anti-Hero\"', '\"Look What You Made Me Do\"', '\"Style\"', '\"Wildest Dreams\"', '\"I Don’t Wanna Live Forever (Fifty Shades Darker)\" with Zayn', '\"Bad Blood\" ft. Kendrick Lamar', '\"We Are Never Ever Getting Back Together\"', '\"I Knew You Were Trouble.\"', '\"Love Story\"', '\"Blank Space\"', '\"You Belong With Me\"', '\"Shake It Off\"']\n",
      "--------------PEAK AT---- \n",
      " ['Swift’s uptempo country jam, the final single off her 2006 self-titled debut, peaked at No. 33 on the Hot 100.', 'The Red duet peaked at No. 32 on the Hot 100 after being released as a single in 2013.', 'Swift’s Hot 100 debut — the country love song that started it all — reached No. 40 on the Hot 100. It also became her first of 21 top 10s to date on Hot Country Songs.', 'The dazzling Midnights track peaked at No. 6 on the Hot 100.', 'The second Hunger Games soundtrack single from Swift, “Eyes Open” peaked at No. 19 on the Hot 100 following its 2012 release.', 'The rockin’ promo single from the 2012 album of the same name exploded onto the Hot 100 at No. 6.', 'The regretful Midnights track peaked at No. 5 on the Hot 100 in November 2022.', 'Swift’s plaintive, banjo-featuring single off Speak Now debuted and peaked at No. 13 on the Hot 100.', 'The loved-up opening Midnights song peaked at No. 2 on the Hot 100.', 'Swift clapped back at her critics (rumors suggest music industry analyst Bob Lefsetz as the specific target) with “Mean,” which debuted (and peaked) at No. 11 in 2010. The track won Swift a pair of Grammys at the 2012 ceremony: best country song and best country solo performance.', 'Swift revisited her roots and, in the process, teamed with the title subject of her debut hit with this feature on McGraw’s 2013 album Two Lanes of Freedom. The collab drove to No. 22 on the Hot 100.', 'This confessional 2009 song — which shouts out the singer’s original #squad member and best friend Abigail Anderson — evidently resonated with teens everywhere, peaking at No. 23.', 'So “Fifteen” is No. 28 and “22” is No. 27. (Got that?) Another age-centric single, another hit, as the Swift/Max Martin collab “22” was the sixth Red single to hit the Hot 100’s top 20, peaking at No. 20.', 'The song gave Swift a fab honor: when it debuted at its No. 4 Hot 100 peak in September 2017, it became Swift’s 72nd Hot 100 entry … one more than The Beatles’ career total.', '“Cardigan,” the lead single from Swift’s pandemic album Folklore, signaled a return to her singer-songwriter roots as she branched out into the indie and folk music realms. Co-written and produced by The National’s Aaron Dessner, “Cardigan” topped the Hot 100.', 'The title track from Swift’s seventh studio album, released in 2019, found strong public reception after a performance on that year’s MTV Video Music Awards. As the album impacted the Billboard charts, the resulting activity pushed this composition to No. 10 on the Hot 100.', 'The Grammy Award-winning track (best country song, best female country vocal performance) galloped to a No. 13 peak on the Hot 100.', 'When Taylor Swift rerecorded her 2012 LP Red in 2021 as Red (Taylor’s Version), she expanded “All Too Well” to its original 10-minute length. The new version topped the Hot 100 and became the longest song to hit No. 1 on that chart.', 'This ode to a dream date, fittingly off 2010’s Valentine’s Day soundtrack, debuted and peaked at No. 2 on the Hot 100.', 'Power-poppers Boys Like Girls brought in Swift for the assist on this 2009 single, which peaked at No. 18 on the Hot 100.', '“Willow,” the lead single from Taylor Swift’s ninth studio album Evermore, debuted at No. 1 on the Hot 100, continuing in the understated folk singer-songwriter vein of her previous album, Folklore.', 'Rumored to be about Swift’s short-lived relationship with Taylor Lautner, the ballad entered and crested at No. 6 on the Hot 100 in 2010.', 'The fourth Reputation single, a gentle, enveloping midtempo ballad, stood in stark contrast with its three immediate predecessors. The switch-up had welcome results, cruising to No. 12 on the Hot 100 while slowly but steadily rising to top the Pop Songs airplay chart.', 'A 180-degree turn from the dark Reputation, “Me!” is a bouncy, celebratory track that finds Swift at her most saccharine sweet alongside Panic! at The Disco frontman Brendon Urie. The pair’s collab, the lead single from Swift’s 2019 album Lover, surged to No. 2 on the Hot 100.', 'As Swift advocated for Democratic political causes in late 2018, the singer infused an overt political tone into her songs for the first time with this 2019 Lover cut. Its lyrics supported LGBTQ causes, feminism and self-empowerment, and secured a No. 2 Hot 100 hit for the singer’s resume. The video, with many LGBTQ stars making cameos, also ended a multi-year feud with Katy Perry, as the two reunite and embrace in the clip.', 'Swift’s third single, released in 2007, climbed to No. 16 on the Hot 100 and became her first of seven No. 1s to date on Hot Country Songs.', 'Swift’s breakout pop crossover single peaked at No. 13 on the Hot 100 in 2008.', 'The lead single off Speak Now — a rollicking country breakup song — made a No. 3 splash on the Hot 100 in 2010.', 'The lead single off Midnights debuted atop the Hot 100, and remained there for six weeks until Mariah Carey’s seasonal classic, “All I Want Is You,” bumped it from the summit on the chart dated Dec. 17, 2022.', 'The lead single from Swift’s fifth No. 1 Billboard 200 album, Reputation, likewise became her fifth No. 1 song on the Hot 100, reaching the summit in September 2017.', 'We’re up to the top 10, where half the titles are from Swift’s pop opus 1989. Entering the chart after Swift performed the track at the 2014 Victoria’s Secret fashion show, the third single from the album peaked at No. 6.', 'The chemistry of Swift, Max Martin and Shellback remained infallible with “Wildest Dreams,” which peaked at No. 5 on the Hot 100 in November 2015.', 'Swift released the brooding Zayn duet as her first post-1989 single. The Fifty Shades Darker song rose to No. 2 on the Hot 100 in March 2017.', 'Fueled by a #squad-flaunting video (and a highly anticipated appearance by Kendrick Lamar), Swift’s diss track hit No. 1 on the Hot 100 for one week following the clip’s debut at the 2015 Billboard Music Awards.', 'Swift’s first Hot 100 No. 1, the critically-acclaimed single confirmed Swift’s crossover appeal, staying at the top for three weeks following its 2012 release.', 'The irresistible anthem from Red debuted at No. 3 on the Hot 100 in October 2012, eventually peaking at No. 2.', 'The melodic masterpiece, and fairytale-themed lead single off Fearless, peaked at No. 4 on the Hot 100 in 2009.', 'Swift became the first woman to replace herself at No. 1 on the Hot 100, as the second single off 1989 dethroned “Shake It Off.” “Blank Space” spent seven weeks on top in 2014-15.', 'The monster crossover hit dominated airwaves in 2009, peaking at No. 2 on the Hot 100. It also became the first country song to top the all-genre Radio Songs chart (after “Love Story” had reached No. 2) since its start in 1990.', 'Swift’s devil-may-care anthem found her unabashedly looking for pop dominance, and she found it: The single debuted at No. 1 on the Hot 100 and posted four weeks at the top. Plus, its nearly six-month stay in the top 10 alone plays a major role in its status as Swift’s biggest charting single in a career with a multitude of milestones.']\n"
     ]
    }
   ],
   "source": [
    "print('-----------TAYLOR SWIFTS SONGS-----------','\\n',songs)\n",
    "print('--------------PEAK AT----','\\n',peak)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c1e0152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SONGS</th>\n",
       "      <th>PEAK AT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Should’ve Said No\"</td>\n",
       "      <td>Swift’s uptempo country jam, the final single ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Everything Has Changed\" ft. Ed Sheeran</td>\n",
       "      <td>The Red duet peaked at No. 32 on the Hot 100 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Tim McGraw\"</td>\n",
       "      <td>Swift’s Hot 100 debut — the country love song ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Bejeweled\"</td>\n",
       "      <td>The dazzling Midnights track peaked at No. 6 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Eyes Open\"</td>\n",
       "      <td>The second Hunger Games soundtrack single from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Red\"</td>\n",
       "      <td>The rockin’ promo single from the 2012 album o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Midnight Rain\"</td>\n",
       "      <td>The regretful Midnights track peaked at No. 5 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Ours\"</td>\n",
       "      <td>Swift’s plaintive, banjo-featuring single off ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Lavender Haze\"</td>\n",
       "      <td>The loved-up opening Midnights song peaked at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Mean\"</td>\n",
       "      <td>Swift clapped back at her critics (rumors sugg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tim McGraw with Taylor Swift, “Highway Don’t C...</td>\n",
       "      <td>Swift revisited her roots and, in the process,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"Fifteen\"</td>\n",
       "      <td>This confessional 2009 song — which shouts out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"22\"</td>\n",
       "      <td>So “Fifteen” is No. 28 and “22” is No. 27. (Go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"...Ready for It?\"</td>\n",
       "      <td>The song gave Swift a fab honor: when it debut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Cardigan\"</td>\n",
       "      <td>“Cardigan,” the lead single from Swift’s pande...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"Lover\"</td>\n",
       "      <td>The title track from Swift’s seventh studio al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"White Horse\"</td>\n",
       "      <td>The Grammy Award-winning track (best country s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"All Too Well (Taylor's Version)\"</td>\n",
       "      <td>When Taylor Swift rerecorded her 2012 LP Red i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Today Was a Fairytale\"</td>\n",
       "      <td>This ode to a dream date, fittingly off 2010’s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Boys Like Girls ft. Taylor Swift, \"Two Is Bett...</td>\n",
       "      <td>Power-poppers Boys Like Girls brought in Swift...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Willow\"</td>\n",
       "      <td>“Willow,” the lead single from Taylor Swift’s ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"Back to December\"</td>\n",
       "      <td>Rumored to be about Swift’s short-lived relati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Delicate\"</td>\n",
       "      <td>The fourth Reputation single, a gentle, envelo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Me!\" ft. Brendon Urie</td>\n",
       "      <td>A 180-degree turn from the dark Reputation, “M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"You Need to Calm Down\"</td>\n",
       "      <td>As Swift advocated for Democratic political ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"Our Song\"</td>\n",
       "      <td>Swift’s third single, released in 2007, climbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Teardrops on My Guitar\"</td>\n",
       "      <td>Swift’s breakout pop crossover single peaked a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Mine\"</td>\n",
       "      <td>The lead single off Speak Now — a rollicking c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"Anti-Hero\"</td>\n",
       "      <td>The lead single off Midnights debuted atop the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>\"Look What You Made Me Do\"</td>\n",
       "      <td>The lead single from Swift’s fifth No. 1 Billb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\"Style\"</td>\n",
       "      <td>We’re up to the top 10, where half the titles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\"Wildest Dreams\"</td>\n",
       "      <td>The chemistry of Swift, Max Martin and Shellba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\"I Don’t Wanna Live Forever (Fifty Shades Dark...</td>\n",
       "      <td>Swift released the brooding Zayn duet as her f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\"Bad Blood\" ft. Kendrick Lamar</td>\n",
       "      <td>Fueled by a #squad-flaunting video (and a high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>\"We Are Never Ever Getting Back Together\"</td>\n",
       "      <td>Swift’s first Hot 100 No. 1, the critically-ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>\"I Knew You Were Trouble.\"</td>\n",
       "      <td>The irresistible anthem from Red debuted at No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>\"Love Story\"</td>\n",
       "      <td>The melodic masterpiece, and fairytale-themed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>\"Blank Space\"</td>\n",
       "      <td>Swift became the first woman to replace hersel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\"You Belong With Me\"</td>\n",
       "      <td>The monster crossover hit dominated airwaves i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>\"Shake It Off\"</td>\n",
       "      <td>Swift’s devil-may-care anthem found her unabas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                SONGS  \\\n",
       "0                                 \"Should’ve Said No\"   \n",
       "1             \"Everything Has Changed\" ft. Ed Sheeran   \n",
       "2                                        \"Tim McGraw\"   \n",
       "3                                         \"Bejeweled\"   \n",
       "4                                         \"Eyes Open\"   \n",
       "5                                               \"Red\"   \n",
       "6                                     \"Midnight Rain\"   \n",
       "7                                              \"Ours\"   \n",
       "8                                     \"Lavender Haze\"   \n",
       "9                                              \"Mean\"   \n",
       "10  Tim McGraw with Taylor Swift, “Highway Don’t C...   \n",
       "11                                          \"Fifteen\"   \n",
       "12                                               \"22\"   \n",
       "13                                 \"...Ready for It?\"   \n",
       "14                                         \"Cardigan\"   \n",
       "15                                            \"Lover\"   \n",
       "16                                      \"White Horse\"   \n",
       "17                  \"All Too Well (Taylor's Version)\"   \n",
       "18                            \"Today Was a Fairytale\"   \n",
       "19  Boys Like Girls ft. Taylor Swift, \"Two Is Bett...   \n",
       "20                                           \"Willow\"   \n",
       "21                                 \"Back to December\"   \n",
       "22                                         \"Delicate\"   \n",
       "23                             \"Me!\" ft. Brendon Urie   \n",
       "24                            \"You Need to Calm Down\"   \n",
       "25                                         \"Our Song\"   \n",
       "26                           \"Teardrops on My Guitar\"   \n",
       "27                                             \"Mine\"   \n",
       "28                                        \"Anti-Hero\"   \n",
       "29                         \"Look What You Made Me Do\"   \n",
       "30                                            \"Style\"   \n",
       "31                                   \"Wildest Dreams\"   \n",
       "32  \"I Don’t Wanna Live Forever (Fifty Shades Dark...   \n",
       "33                     \"Bad Blood\" ft. Kendrick Lamar   \n",
       "34          \"We Are Never Ever Getting Back Together\"   \n",
       "35                         \"I Knew You Were Trouble.\"   \n",
       "36                                       \"Love Story\"   \n",
       "37                                      \"Blank Space\"   \n",
       "38                               \"You Belong With Me\"   \n",
       "39                                     \"Shake It Off\"   \n",
       "\n",
       "                                              PEAK AT  \n",
       "0   Swift’s uptempo country jam, the final single ...  \n",
       "1   The Red duet peaked at No. 32 on the Hot 100 a...  \n",
       "2   Swift’s Hot 100 debut — the country love song ...  \n",
       "3   The dazzling Midnights track peaked at No. 6 o...  \n",
       "4   The second Hunger Games soundtrack single from...  \n",
       "5   The rockin’ promo single from the 2012 album o...  \n",
       "6   The regretful Midnights track peaked at No. 5 ...  \n",
       "7   Swift’s plaintive, banjo-featuring single off ...  \n",
       "8   The loved-up opening Midnights song peaked at ...  \n",
       "9   Swift clapped back at her critics (rumors sugg...  \n",
       "10  Swift revisited her roots and, in the process,...  \n",
       "11  This confessional 2009 song — which shouts out...  \n",
       "12  So “Fifteen” is No. 28 and “22” is No. 27. (Go...  \n",
       "13  The song gave Swift a fab honor: when it debut...  \n",
       "14  “Cardigan,” the lead single from Swift’s pande...  \n",
       "15  The title track from Swift’s seventh studio al...  \n",
       "16  The Grammy Award-winning track (best country s...  \n",
       "17  When Taylor Swift rerecorded her 2012 LP Red i...  \n",
       "18  This ode to a dream date, fittingly off 2010’s...  \n",
       "19  Power-poppers Boys Like Girls brought in Swift...  \n",
       "20  “Willow,” the lead single from Taylor Swift’s ...  \n",
       "21  Rumored to be about Swift’s short-lived relati...  \n",
       "22  The fourth Reputation single, a gentle, envelo...  \n",
       "23  A 180-degree turn from the dark Reputation, “M...  \n",
       "24  As Swift advocated for Democratic political ca...  \n",
       "25  Swift’s third single, released in 2007, climbe...  \n",
       "26  Swift’s breakout pop crossover single peaked a...  \n",
       "27  The lead single off Speak Now — a rollicking c...  \n",
       "28  The lead single off Midnights debuted atop the...  \n",
       "29  The lead single from Swift’s fifth No. 1 Billb...  \n",
       "30  We’re up to the top 10, where half the titles ...  \n",
       "31  The chemistry of Swift, Max Martin and Shellba...  \n",
       "32  Swift released the brooding Zayn duet as her f...  \n",
       "33  Fueled by a #squad-flaunting video (and a high...  \n",
       "34  Swift’s first Hot 100 No. 1, the critically-ac...  \n",
       "35  The irresistible anthem from Red debuted at No...  \n",
       "36  The melodic masterpiece, and fairytale-themed ...  \n",
       "37  Swift became the first woman to replace hersel...  \n",
       "38  The monster crossover hit dominated airwaves i...  \n",
       "39  Swift’s devil-may-care anthem found her unabas...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'SONGS':songs,'PEAK AT':peak})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7cc7bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------TOP SONGS WITH ARTIST NAME-------------------------- \n",
      " ['Tariq, The Gregory Brothers & Recess Therapy, \"It\\'s Corn\"', 'Grupo Firme & Camilo, \"Alaska\"', 'Blondshell, \"Olympus\"', 'Nicky Youre & dazy, \"Sunroof\"', 'MICHELLE, \"Pose\"', 'd4vd, \"Romantic Homicide\"', 'Kaytranada & Anderson .Paak, \"Twin Flame\"', 'Central Cee, \"Doja\"', 'Rauw Alejandro, \"Dime Quién ????\"', 'BLACKPINK, \"Shut Down\"', 'Eliza Rose & Interplanetary Criminal, \"B.O.T.A. (Baddest of Them All)\"', 'Anitta, \"Envolver\"', 'Doechii & SZA, \"Persuasive\"', 'Kelela, \"Happy Ending\"', 'HitKidd & GloRilla, \"F.N.F.\"', 'FLO, \"Cardboard Box\"', 'beabadoobee, \"Talk\"', 'Lil Uzi Vert, \"Just Wanna Rock\"', 'Carly Rae Jepsen feat. Rufus Wainwright, \"The Loneliest Time\"', 'Lil Nas X, \"Thats What I Want\"', 'Cody Johnson, \"\\'Til You Can\\'t\"', 'Elton John & Britney Spears, \"Hold Me Closer\"', 'Chappell Roan, \"Casual\"', 'Orville Peck, \"C\\'mon Baby, Cry\"', 'Florence + the Machine, \"King\"', 'Lizzo, \"2 Be Loved (Am I Ready)\"', 'Vince Staples & Mustard, \"Magic\"', 'Tove Lo, \"No One Dies From Love\"', 'Wizkid, \"Bad to Me\"', 'Ice Spice, \"Munch (Feelin\\' U)\"', 'Grupo Frontera, \"No Se Va\"', 'Taylor Swift, \"Lavender Haze\"', 'Rina Sawayama, \"This Hell\"', 'Kendrick Lamar feat. Blxst and Amanda Reifer, \"Die Hard\"', 'GAYLE, \"abcdefu\"', 'HARDY feat. Lainey Wilson, \"Wait in the Truck\"', 'Megan Thee Stallion, \"Plan B\"', 'Charlie Puth, \"Light Switch\"', 'Fred again.. feat. Romy & HAAi, \"Lights Out\"', 'Pharrell Williams feat. 21 Savage & Tyler, the Creator, \"Cash In Cash Out\"', 'Rosalía, \"Despecha\"', 'Maren Morris, \"Circles Around This Town\"', 'Quavo & Takeoff, \"Hotel Lobby (Unc and Phew)\"', 'Phoebe Bridgers, \"Sidelines\"', 'Becky G & Karol G, \"MAMIII\"', 'Mitski, \"Love Me More\"', 'Rihanna, \"Lift Me Up\"', 'Lil Yachty, \"Poland\"', 'Alex G, \"Runner\"', 'Latto, \"Big Energy\"', 'Shervin Hajipour, \"Baraye\"', 'Let\\'s Eat Grandma, \"Happy New Year\"', 'Beyoncé, \"Alien Superstar\"', 'Yahritza y Su Esencia, \"Soy el Unico\"', 'Brandi Carlile feat. Lucius, \"You and Me on the Rock\"', 'Arctic Monkeys, \"There\\'d Better Be a Mirrorball\"', 'Bizarrap & Quevedo, \"Bzrp Music Sessions, Vol. 52\"', 'Soccer Mommy, \"Shotgun\"', 'Maggie Rogers, \"That\\'s Where I Am\"', 'Omar Apollo, \"Tamagotchi\"', 'Drake, \"Sticky\"', 'Doja Cat, \"Vegas\"', 'Paramore, \"This Is Why\"', 'Sabrina Carpenter, \"Vicious\"', 'Charli XCX feat. Rina Sawayama, \"Beg for You\"', 'Nicki Minaj, \"Super Freaky Girl\"', 'Muni Long, \"Hrs and Hrs\"', 'Jessie Ware, \"Free Yourself\"', 'Burna Boy, \"Last Last\"', 'MUNA, \"Anything But Me\"', 'The Weeknd, \"Out of Time\"', 'Yeah Yeah Yeahs feat. Perfume Genius, \"Spitting Off the Edge of the World\"', 'Post Malone feat. Doja Cat, \"I Like You (A Happier Song)\"', 'Bad Bunny, \"Moscow Mule\"', 'Jack Harlow, \"First Class\"', 'The 1975, \"Happiness\"', 'Gunna & Future feat. Young Thug, \"Pushin P\"', 'Karol G, \"Provenza\"', 'Zach Bryan, \"Something in the Orange\"', 'Ethel Cain, \"American Teenager\"', 'Harry Styles, \"Music for a Sushi Restaurant\"', 'Wet Leg, \"Wet Dream\"', 'Joji, \"Glimpse of Us\"', 'Doja Cat, \"Woman\"', 'Sam Smith & Kim Petras, \"Unholy\"', 'Beyoncé, \"Cuff It\"', 'Future feat. Drake & Tems, \"Wait for U\"', 'SZA, \"Shirt\"', 'GloRilla & Cardi B, \"Tomorrow 2\"', 'Carolina Gaitan, Mauro Castillo, Adassa, Rhenzy Feliz, Diane Guerrero, Stephanie Beatriz & ‘Encanto’ Cast, \"We Don\\'t Talk About Bruno\"', 'Dove Cameron, \"Boyfriend\"', 'Tems, \"Free Mind\"', 'Rosalía, \"Saoko\"', 'Kendrick Lamar, \"N95\"', 'Bad Bunny, \"Tití Me Preguntó\"', 'Taylor Swift, \"Anti-Hero\"', 'Lizzo, \"About Damn Time\"', 'Harry Styles, \"As It Was\"', 'Beyoncé, \"Break My Soul\"', 'Steve Lacy, \"Bad Habit\"']\n"
     ]
    }
   ],
   "source": [
    "topsongs=[]\n",
    "for i in driver.find_elements(By.XPATH,'//h2[@class=\"c-gallery-vertical-featured-image__title\"]'):\n",
    "    topsongs.append(i.text)\n",
    "print('----------------------TOP SONGS WITH ARTIST NAME--------------------------','\\n',topsongs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996382a",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e89014a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\phyed\\Desktop\\FLIP ROBO ASSIGNMENT\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "56c18679",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c54bf05e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//select[@name='Economy']\"}\n  (Session info: chrome=108.0.5359.125)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00F4F243]\n\t(No symbol) [0x00ED7FD1]\n\t(No symbol) [0x00DCD04D]\n\t(No symbol) [0x00DFC0B0]\n\t(No symbol) [0x00DFC22B]\n\t(No symbol) [0x00E2E612]\n\t(No symbol) [0x00E185D4]\n\t(No symbol) [0x00E2C9EB]\n\t(No symbol) [0x00E18386]\n\t(No symbol) [0x00DF163C]\n\t(No symbol) [0x00DF269D]\n\tGetHandleVerifier [0x011E9A22+2655074]\n\tGetHandleVerifier [0x011DCA24+2601828]\n\tGetHandleVerifier [0x00FF8C0A+619850]\n\tGetHandleVerifier [0x00FF7830+614768]\n\t(No symbol) [0x00EE05FC]\n\t(No symbol) [0x00EE5968]\n\t(No symbol) [0x00EE5A55]\n\t(No symbol) [0x00EF051B]\n\tBaseThreadInitThunk [0x758C7D69+25]\n\tRtlInitializeExceptionChain [0x7764BB9B+107]\n\tRtlClearBits [0x7764BB1F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# identify dropdown with Select class\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m sel \u001b[38;5;241m=\u001b[39m Select(\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m//select[@name=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEconomy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#select by select_by_visible_text() method\u001b[39;00m\n\u001b[0;32m      6\u001b[0m sel\u001b[38;5;241m.\u001b[39mselect_by_visible_text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndia\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:861\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    858\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    859\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[1;32m--> 861\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:444\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    442\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:249\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    247\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//select[@name='Economy']\"}\n  (Session info: chrome=108.0.5359.125)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00F4F243]\n\t(No symbol) [0x00ED7FD1]\n\t(No symbol) [0x00DCD04D]\n\t(No symbol) [0x00DFC0B0]\n\t(No symbol) [0x00DFC22B]\n\t(No symbol) [0x00E2E612]\n\t(No symbol) [0x00E185D4]\n\t(No symbol) [0x00E2C9EB]\n\t(No symbol) [0x00E18386]\n\t(No symbol) [0x00DF163C]\n\t(No symbol) [0x00DF269D]\n\tGetHandleVerifier [0x011E9A22+2655074]\n\tGetHandleVerifier [0x011DCA24+2601828]\n\tGetHandleVerifier [0x00FF8C0A+619850]\n\tGetHandleVerifier [0x00FF7830+614768]\n\t(No symbol) [0x00EE05FC]\n\t(No symbol) [0x00EE5968]\n\t(No symbol) [0x00EE5A55]\n\t(No symbol) [0x00EF051B]\n\tBaseThreadInitThunk [0x758C7D69+25]\n\tRtlInitializeExceptionChain [0x7764BB9B+107]\n\tRtlClearBits [0x7764BB1F+191]\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "# identify dropdown with Select class\n",
    "sel = Select(driver.find_element(By.XPATH,\"//select[@name='Economy']\"))\n",
    "#select by select_by_visible_text() method\n",
    "sel.select_by_visible_text(\"India\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "87c21434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Gujarat',\n",
       " 'Karnataka',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Andhra Pradesh',\n",
       " 'Telangana',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Chhattisgarh',\n",
       " 'Jharkhand',\n",
       " 'Uttarakhand',\n",
       " 'Jammu & Kashmir',\n",
       " 'Himachal Pradesh',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Sikkim']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state=[]\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"name\"]')[0:28]:\n",
    "    state.append(i.text)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "136da1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '13.94%',\n",
       " '399.921',\n",
       " '-',\n",
       " '2,039,074',\n",
       " '1,845,853',\n",
       " '8.63%',\n",
       " '247.629',\n",
       " '1,312,929',\n",
       " '1,215,307',\n",
       " '1,687,818',\n",
       " '8.39%',\n",
       " '240.726',\n",
       " '1,166,817',\n",
       " '1,123,982',\n",
       " '-',\n",
       " '7.96%',\n",
       " '228.290',\n",
       " '-',\n",
       " '1,186,379',\n",
       " '1,631,977',\n",
       " '7.91%',\n",
       " '226.806',\n",
       " '1,156,039',\n",
       " '1,091,077',\n",
       " '1,253,832',\n",
       " '5.77%',\n",
       " '165.556']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdp=[]\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"data\"]')[0:28]:\n",
    "    gsdp.append(i.text)\n",
    "gsdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5f4d6b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,632,792',\n",
       " '1,630,208',\n",
       " '1,584,764',\n",
       " '1,502,899',\n",
       " '1,493,127',\n",
       " '1,089,898',\n",
       " '942,586',\n",
       " '862,957',\n",
       " '861,031',\n",
       " '809,592',\n",
       " '781,653',\n",
       " '774,870',\n",
       " '734,163',\n",
       " '530,363',\n",
       " '526,376',\n",
       " '487,805',\n",
       " '315,881',\n",
       " '304,063',\n",
       " '297,204',\n",
       " '245,895',\n",
       " '155,956',\n",
       " '153,845',\n",
       " '73,170',\n",
       " '49,845',\n",
       " '42,114',\n",
       " '34,433',\n",
       " '33,481',\n",
       " '28,723']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdp2=[]\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"data sorting_1\"]')[0:28]:\n",
    "    gsdp2.append(i.text)\n",
    "gsdp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8fcbda73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>gsdp(19-20)</th>\n",
       "      <th>gsdp(18-19)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>1,630,208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>399.921</td>\n",
       "      <td>1,584,764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,039,074</td>\n",
       "      <td>1,493,127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,089,898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>942,586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>247.629</td>\n",
       "      <td>862,957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,312,929</td>\n",
       "      <td>861,031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,215,307</td>\n",
       "      <td>809,592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kerala</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>781,653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>774,870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>240.726</td>\n",
       "      <td>734,163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bihar</td>\n",
       "      <td>1,166,817</td>\n",
       "      <td>530,363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Punjab</td>\n",
       "      <td>1,123,982</td>\n",
       "      <td>526,376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Odisha</td>\n",
       "      <td>-</td>\n",
       "      <td>487,805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Assam</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>315,881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>228.290</td>\n",
       "      <td>304,063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>-</td>\n",
       "      <td>297,204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>1,186,379</td>\n",
       "      <td>245,895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>155,956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>153,845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Goa</td>\n",
       "      <td>226.806</td>\n",
       "      <td>73,170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Tripura</td>\n",
       "      <td>1,156,039</td>\n",
       "      <td>49,845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>1,091,077</td>\n",
       "      <td>42,114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Puducherry</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>34,433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>33,481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sikkim</td>\n",
       "      <td>165.556</td>\n",
       "      <td>28,723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               state gsdp(19-20) gsdp(18-19)\n",
       "0        Maharashtra           -   2,632,792\n",
       "1         Tamil Nadu      13.94%   1,630,208\n",
       "2      Uttar Pradesh     399.921   1,584,764\n",
       "3            Gujarat           -   1,502,899\n",
       "4          Karnataka   2,039,074   1,493,127\n",
       "5        West Bengal   1,845,853   1,089,898\n",
       "6          Rajasthan       8.63%     942,586\n",
       "7     Andhra Pradesh     247.629     862,957\n",
       "8          Telangana   1,312,929     861,031\n",
       "9     Madhya Pradesh   1,215,307     809,592\n",
       "10            Kerala   1,687,818     781,653\n",
       "11             Delhi       8.39%     774,870\n",
       "12           Haryana     240.726     734,163\n",
       "13             Bihar   1,166,817     530,363\n",
       "14            Punjab   1,123,982     526,376\n",
       "15            Odisha           -     487,805\n",
       "16             Assam       7.96%     315,881\n",
       "17      Chhattisgarh     228.290     304,063\n",
       "18         Jharkhand           -     297,204\n",
       "19       Uttarakhand   1,186,379     245,895\n",
       "20   Jammu & Kashmir   1,631,977     155,956\n",
       "21  Himachal Pradesh       7.91%     153,845\n",
       "22               Goa     226.806      73,170\n",
       "23           Tripura   1,156,039      49,845\n",
       "24        Chandigarh   1,091,077      42,114\n",
       "25        Puducherry   1,253,832      34,433\n",
       "26         Meghalaya       5.77%      33,481\n",
       "27            Sikkim     165.556      28,723"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'state':state,'gsdp(19-20)':gsdp,'gsdp(18-19)':gsdp2})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2d38131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:-\n",
      "data:2,632,792\n",
      "data:13.94%\n",
      "data:399.921\n",
      "data:-\n",
      "data:2,039,074\n",
      "data:1,845,853\n",
      "data:1,630,208\n",
      "data:8.63%\n",
      "data:247.629\n",
      "data:1,312,929\n",
      "data:1,215,307\n",
      "data:1,687,818\n",
      "data:1,584,764\n",
      "data:8.39%\n",
      "data:240.726\n",
      "data:1,166,817\n",
      "data:1,123,982\n",
      "data:-\n",
      "data:1,502,899\n",
      "data:7.96%\n",
      "data:228.290\n",
      "data:-\n",
      "data:1,186,379\n",
      "data:1,631,977\n",
      "data:1,493,127\n",
      "data:7.91%\n",
      "data:226.806\n"
     ]
    }
   ],
   "source": [
    "#Share,gdp,gsdp info are scrapped by following method----\n",
    "# identify elements of same classname\n",
    "l=driver.find_elements(By.CLASS_NAME,\"data\")\n",
    "# iterate through list and get text\n",
    "for i in l[0:28]:\n",
    "   print(\"data:\"+ i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44833e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
